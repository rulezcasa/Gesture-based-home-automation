{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c7e269",
   "metadata": {},
   "source": [
    "## Importing data manipulation libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b3a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib.image import imread\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D,Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0bc4db",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e5b77b",
   "metadata": {},
   "source": [
    "Custom curated dataset includiing 476 images.\n",
    "Hand-signs are annotated in folder format.\n",
    "\n",
    "The following pre-processing was applied to each image:\n",
    "* Auto-orientation of pixel data (with EXIF-orientation stripping)\n",
    "* Resize to 640x640 (Stretch)\n",
    "\n",
    "The following augmentation was applied to create 3 versions of each source image:\n",
    "* Randomly crop between 0 and 25 percent of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def1d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/Users/casarulez/Projects/IoT /dataset-annotated/train\"\n",
    "test_dir = \"/Users/casarulez/Projects/IoT /dataset-annotated/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6cacfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_samples(directory):\n",
    "    classes = os.listdir(directory)\n",
    "    fig, axes = plt.subplots(len(classes), 4, figsize=(16, 16))\n",
    "\n",
    "    for i, class_name in enumerate(classes):\n",
    "        if class_name == \".DS_Store\":  # Skip .DS_Store directory\n",
    "            continue\n",
    "        \n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        img_names = os.listdir(class_dir)[:4]  # Load the first four images from each class\n",
    "        for j, img_name in enumerate(img_names):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            img = imread(img_path)\n",
    "            axes[i, j].imshow(img)\n",
    "            axes[i, j].set_title(class_name)\n",
    "            axes[i, j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5a1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from the training dataset\n",
    "display_samples(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd151cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    classes = sorted(os.listdir(directory))  # Assuming classes are named as directories\n",
    "    for i, class_name in enumerate(classes):\n",
    "        if class_name == '.DS_Store':  # Skip .DS_Store file if present\n",
    "            continue\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename == '.DS_Store':  # Skip .DS_Store file if present\n",
    "                continue\n",
    "            img_path = os.path.join(class_dir, filename)\n",
    "            img = cv2.imread(img_path)  # Read image\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB (if needed)\n",
    "            images.append(img)\n",
    "            labels.append(i-1)  # Assign label based on class index\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e80d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "train_images, train_labels = load_data(train_dir)\n",
    "test_images, test_labels = load_data(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6813422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display shape of arrays\n",
    "print(\"Shape of train images array:\", train_images.shape)\n",
    "print(\"Shape of train labels array:\", train_labels.shape)\n",
    "print(\"Shape of test images array:\", test_images.shape)\n",
    "print(\"Shape of test labels array:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cbeaf5-9125-423e-86a8-380d09317131",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a497685",
   "metadata": {},
   "source": [
    "## Defining model architecture  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb903e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load MobileNetV2 pre-trained model without the top classification layer\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(640, 640, 3))\n",
    "\n",
    "# Freeze the base model layers to prevent them from being updated during training\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom classification head\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(128, activation='gelu')(x)  # Add additional dense layer if needed\n",
    "predictions = Dense(4, activation='softmax')(x)  # Adjust the number of classes (4 in this example)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed96484",
   "metadata": {},
   "source": [
    "## Fitting the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5626f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the model for a given number of epochs (iterations on a dataset) and validates it.\n",
    "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(train_images, train_labels)\n",
    "print('Train data accuracy: {:.2f}%'.format(train_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4491a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test data accuracy: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2ecdb4-2774-45b2-abcf-96d192602d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the image\n",
    "image_path = '/Users/casarulez/Downloads/ls.jpg'  # Corrected file path\n",
    "image = cv2.imread(image_path)\n",
    "image = image.astype('float32') / 255.0  # Normalize the pixel values to [0, 1]\n",
    "\n",
    "# Expand dimensions to create a batch of size 1\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "# Make prediction\n",
    "predictions = model.predict(image)\n",
    "\n",
    "# Display the predictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8950307c-fca5-4fe7-b893-b16414f1a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming predictions is a NumPy array containing probabilities for each class\n",
    "# Each row of predictions corresponds to the predicted probabilities for one sample\n",
    "\n",
    "# Assuming label_names is a list of label names corresponding to the classes\n",
    "label_names = ['Fan', 'OFF', 'ON', 'light']  # Update with your actual label names\n",
    "\n",
    "# Predict the labels for the test set\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Map the predicted label indices to their corresponding label names\n",
    "predicted_label_names = [label_names[label_index] for label_index in predicted_labels]\n",
    "\n",
    "# Display the predicted label names\n",
    "print(\"Predicted label names:\", predicted_label_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75148b16",
   "metadata": {},
   "source": [
    "## Video capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3706dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess a single image\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (640, 640))  # Resize the image to match the model input size\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "# Function to overlay class probabilities on the image as text\n",
    "def overlay_class_probabilities(image, predictions):\n",
    "    classes = ['Fan', 'OFF', 'ON', 'light']  # Update with your actual class names\n",
    "    if predictions.any():  # Check if any element in predictions array is nonzero\n",
    "        probabilities = predictions[0]  # Extract probabilities from the array\n",
    "        for i, prob in enumerate(probabilities):\n",
    "            text = f'{classes[i]}: {prob:.2f}'  # Format probability to two decimal places\n",
    "            cv2.putText(image, text, (10, 30 + i * 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    return image\n",
    "# Load and preprocess the image\n",
    "image_path = '/Users/casarulez/Downloads/off.jpg'  # Corrected file path\n",
    "image = cv2.imread(image_path)\n",
    "image = image.astype('float32') / 255.0  # Normalize the pixel values to [0, 1]\n",
    "\n",
    "# Expand dimensions to create a batch of size 1\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "# Make prediction\n",
    "predictions = model.predict(image)\n",
    "\n",
    "# Display the predictions\n",
    "print(predictions)\n",
    "\n",
    "# Overlay class probabilities on the image\n",
    "output_image = overlay_class_probabilities(image.copy(), predictions)\n",
    "\n",
    "# Display the original and output images\n",
    "cv2.imshow('Original Image', cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "cv2.imshow('Output Image', cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70621a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
